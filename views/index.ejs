<html>
    <head>
            
    </head>
    <input type="button" onclick="create()">
<body>

asdf

<script>
async function create(){
stream = await navigator.mediaDevices.getUserMedia({
        audio:  {autoGainControl: false,
        echoCancellation: false,    //geting microphne permision and stream 
        latency: 0,
        noiseSuppression: false,
        video: false
        }
    });

audioContext = new AudioContext(audioContextOptions = {latencyHint: 0,sampleRate: 48000});
audioSource = audioContext.createMediaStreamSource(stream);     //
await audioContext.audioWorklet.addModule('views/dataSenderProcessor.js')       //registering a new js file a a thread to work with audio data
localProcessingNode = new DataSenderNode(audioContext)
audioSource.connect(localProcessingNode)        //registring microphone stream with thread 

localProcessingNode.port.onmessage=(e)=>{       //event to recive the data from thread 
console.log(e.data)                           //reciving audio data from audio procesing thread 
}
}
class DataSenderNode extends AudioWorkletNode {

    constructor(context) {

        super(context, 'data-sender-processor');
        

    }
}

</script>
</body>

</html>